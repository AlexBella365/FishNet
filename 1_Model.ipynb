{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ROOT = os.path.join(os.getcwd(),'img')\n",
    "img_folders = {\n",
    "    'clown':os.path.join(ROOT,'clown'),\n",
    "    'reef':os.path.join(ROOT,'reef')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RESULT = {\n",
    "    0:'Clown Fish',\n",
    "    1:'No clown fish'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All in one loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_collate(batch):\n",
    "    data = [item[0] for item in batch]\n",
    "    target = [item[1] for item in batch]\n",
    "    target = torch.LongTensor(target)\n",
    "    return [data, target]\n",
    "\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.Resize(size=64),\n",
    "                                       transforms.CenterCrop(size=64),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       ])\n",
    "\n",
    "# change root to valid dir in your system, see ImageFolder documentation for more info\n",
    "dataset = datasets.ImageFolder(root=ROOT,\n",
    "                                    transform=train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = round(len(dataset)*0.7)\n",
    "indices = list(range(len(dataset)))\n",
    "train_ids = np.random.choice(indices,size=N,replace=False)\n",
    "test_ids = list(set(indices) - set(train_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "train_sampler = SubsetRandomSampler(train_ids)\n",
    "test_sampler = SubsetRandomSampler(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset = DataLoader(dataset=dataset,\n",
    "                      batch_size=8,\n",
    "                      #shuffle=True,\n",
    "                      sampler = train_sampler\n",
    "                      #collate_fn=my_collate # use custom collate function here\n",
    "                      )\n",
    "testset = DataLoader(dataset=dataset,\n",
    "                      batch_size=2,\n",
    "                        #shuffle=True,\n",
    "                      sampler = test_sampler\n",
    "                      )\n",
    "\n",
    "trainiter = iter(trainset)\n",
    "imgs, labels = trainiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No clown fish\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAAkKUlEQVR4nHWayZMlSX7Xfz93jz3e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\nyf8GzOzdL5Pu6gQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x1115500B8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = imgs[0]\n",
    "print(RESULT[labels[0].item()])\n",
    "transforms.ToPILImage()(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def abs_size(x):\n",
    "    S = x.size()\n",
    "    result = 1\n",
    "    for s in S[1:]:\n",
    "        result *= s\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FishNet(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (apool): AdaptiveAvgPool2d(output_size=8)\n",
       "  (fc1): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (fc3): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FishNet(nn.Module):\n",
    "    def __init__(self,number_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.apool = nn.AdaptiveAvgPool2d(8)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 16, 128)     # 8x8 square output, 16 layers\n",
    "        self.fc2 = nn.Linear(128, 32)\n",
    "        self.fc3 = nn.Linear(32, number_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.apool(x)\n",
    "        x = x.view(-1, abs_size(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "mynet = FishNet(2)\n",
    "mynet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(mynet.parameters(), lr=0.01, momentum=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, decay_factor=0.1):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] *= decay_factor\n",
    "        \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_stagnant(L,n=10,eps=1e-2):\n",
    "    M1 = np.mean(L[-2*n:-n])\n",
    "    M2 = np.mean(L[-n:])\n",
    "    D = (M1-M2)/(M1+M2)\n",
    "    return abs(D)<eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TO DO\n",
    "#optim.lr_scheduler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LOSSES = []\n",
    "EPOCH_ELAPSED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ---------- Epoch 100 ----------\n",
      "     Batch 08 | Loss: 0.0217\n"
     ]
    }
   ],
   "source": [
    "print_batch = 8\n",
    "N_epoch = 50\n",
    "epochs_since_last_decay = 0\n",
    "decay = 5\n",
    "\n",
    "for epoch in range(1,N_epoch+1):  # loop over the dataset multiple times\n",
    "    \n",
    "    print('\\n','---------- Epoch {:03d} ----------'.format(EPOCH_ELAPSED))\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(trainset, 1):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = mynet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item() #loss.data[0] deprecated in newer versions of PyTorch\n",
    "        if i % print_batch == 0:    # print every few mini-batches\n",
    "            LOSSES.append(running_loss)\n",
    "            print('     Batch {:02d} | Loss: {:.4f}'.format(i ,running_loss / print_batch))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    # Decay LR when learning is stalling, for better convergence\n",
    "    if epochs_since_last_decay>5 and is_stagnant(LOSSES,3):\n",
    "        optimizer = adjust_learning_rate(optimizer,decay_factor=1.0/decay)\n",
    "        epochs_since_last_decay = 0\n",
    "        print('\\n','='*10,'LR decayed by',decay,'='*10,'\\n')\n",
    "    \n",
    "    # Some updating\n",
    "    epochs_since_last_decay += 1\n",
    "    EPOCH_ELAPSED += 1\n",
    "            \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(LOSSES)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20180711_14h10'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now().strftime('%Y%m%d_%Hh%M')\n",
    "now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type FishNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(mynet.state_dict,'FishNet_'+now+'.pth')\n",
    "#torch.save(mynet,'FishNet_'+now+'.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FishNet_20180705_21h41.pth',\n",
       " 'FishNet_20180705_22h31.pth',\n",
       " 'FishNet_20180706_07h25.pth',\n",
       " 'FishNet_20180706_07h36.pth',\n",
       " 'FishNet_20180709_08h16.pth',\n",
       " 'FishNet_20180711_14h03.pth']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_path = glob.glob('*.pth')\n",
    "models_path.sort()\n",
    "models_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1.weight',\n",
       "              tensor([[[[ 0.1827,  0.0666,  0.1475,  0.2291,  0.0944],\n",
       "                        [ 0.1144,  0.0808,  0.0883,  0.0557,  0.0688],\n",
       "                        [ 0.1770,  0.1955,  0.1426,  0.0739,  0.2031],\n",
       "                        [ 0.0724,  0.1473,  0.0520,  0.0570,  0.1219],\n",
       "                        [ 0.1525,  0.0946,  0.2011,  0.1029,  0.2107]],\n",
       "              \n",
       "                       [[ 0.0051,  0.0512, -0.0600, -0.0207,  0.0070],\n",
       "                        [-0.1841, -0.1185,  0.0079, -0.0337, -0.1430],\n",
       "                        [-0.1490, -0.0328,  0.0068,  0.0117, -0.1631],\n",
       "                        [ 0.0054,  0.0070, -0.1415, -0.0726, -0.0273],\n",
       "                        [-0.0170, -0.0167, -0.0994, -0.1464, -0.1355]],\n",
       "              \n",
       "                       [[-0.1686, -0.1674, -0.0122, -0.0721, -0.0591],\n",
       "                        [-0.1927, -0.2009, -0.0852, -0.1690, -0.2181],\n",
       "                        [-0.2399, -0.1581, -0.1297, -0.1127, -0.1652],\n",
       "                        [-0.2179, -0.0719, -0.1993, -0.2220, -0.1690],\n",
       "                        [-0.0662, -0.1978, -0.1275, -0.1971, -0.0401]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1714, -0.1538, -0.1210, -0.0758, -0.1589],\n",
       "                        [-0.2582, -0.1932, -0.1585, -0.2341, -0.2339],\n",
       "                        [-0.1304, -0.2172, -0.2759, -0.2763, -0.0816],\n",
       "                        [-0.1718, -0.1060, -0.2706, -0.2584, -0.0315],\n",
       "                        [ 0.0050, -0.0248, -0.0565, -0.0188, -0.1503]],\n",
       "              \n",
       "                       [[-0.1006,  0.0463, -0.0469, -0.0265, -0.0565],\n",
       "                        [-0.0753, -0.1353, -0.0601, -0.0352, -0.0962],\n",
       "                        [ 0.0005,  0.0280,  0.0714,  0.0094,  0.0760],\n",
       "                        [ 0.0740, -0.1124,  0.0186,  0.0523, -0.0599],\n",
       "                        [-0.0109, -0.0276,  0.0089, -0.0366,  0.0810]],\n",
       "              \n",
       "                       [[ 0.1866,  0.2629,  0.1303,  0.2329,  0.1717],\n",
       "                        [ 0.1516,  0.1074,  0.1463,  0.1436,  0.1652],\n",
       "                        [ 0.1740,  0.1599,  0.1613,  0.1341,  0.1944],\n",
       "                        [ 0.1281,  0.0857,  0.1606,  0.2252,  0.1076],\n",
       "                        [ 0.1863,  0.1239,  0.1298,  0.1990,  0.0120]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0934,  0.1018,  0.0489,  0.1656,  0.0351],\n",
       "                        [ 0.1040,  0.1910,  0.1223,  0.2135,  0.1068],\n",
       "                        [ 0.2016,  0.1290,  0.1423,  0.2134,  0.1055],\n",
       "                        [ 0.1729,  0.0613,  0.2068,  0.1716,  0.0208],\n",
       "                        [ 0.0806,  0.1984,  0.1421,  0.1839,  0.0597]],\n",
       "              \n",
       "                       [[ 0.1197,  0.0826, -0.1224, -0.0098, -0.0700],\n",
       "                        [-0.1213,  0.0425, -0.0536, -0.0433, -0.0820],\n",
       "                        [-0.0483, -0.1165, -0.0773, -0.1040,  0.0382],\n",
       "                        [-0.1063, -0.1093, -0.0382,  0.0215,  0.1246],\n",
       "                        [-0.0303, -0.0904, -0.1101,  0.0294,  0.1152]],\n",
       "              \n",
       "                       [[-0.0344, -0.2109, -0.2711, -0.2441, -0.1686],\n",
       "                        [-0.1846, -0.2593, -0.1311, -0.2401, -0.0070],\n",
       "                        [-0.1632, -0.1375, -0.2957, -0.1177,  0.0488],\n",
       "                        [-0.0971, -0.2993, -0.1368, -0.1080,  0.1075],\n",
       "                        [-0.0195, -0.1514, -0.0268, -0.0190,  0.0901]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0716,  0.0552, -0.0649,  0.0582, -0.0095],\n",
       "                        [-0.0026,  0.0705, -0.0854,  0.0955, -0.0016],\n",
       "                        [ 0.0136,  0.0174,  0.0856, -0.1014,  0.0849],\n",
       "                        [ 0.0688,  0.0500,  0.0559, -0.0370,  0.0335],\n",
       "                        [-0.0921,  0.0107,  0.0781, -0.0062, -0.0862]],\n",
       "              \n",
       "                       [[-0.0905,  0.0288, -0.0785,  0.1221, -0.0024],\n",
       "                        [ 0.0948,  0.0699, -0.1275, -0.0096,  0.0287],\n",
       "                        [ 0.0372, -0.0320, -0.0237,  0.0696, -0.0611],\n",
       "                        [ 0.0740,  0.0271,  0.0202, -0.0015,  0.0140],\n",
       "                        [-0.0494, -0.1311,  0.0525,  0.0517, -0.1005]],\n",
       "              \n",
       "                       [[-0.0278,  0.0779,  0.0181,  0.1522,  0.0342],\n",
       "                        [-0.1049, -0.0620,  0.0438,  0.0076,  0.1358],\n",
       "                        [-0.0922, -0.0556, -0.0280,  0.0911,  0.1232],\n",
       "                        [-0.0106,  0.1051,  0.1134, -0.0160, -0.0385],\n",
       "                        [ 0.0613, -0.1228, -0.0037, -0.0885,  0.0761]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1090, -0.0975,  0.0340, -0.0928,  0.0111],\n",
       "                        [-0.0887, -0.0613, -0.0709,  0.0860,  0.1060],\n",
       "                        [-0.0120, -0.0634,  0.0071,  0.0859, -0.0803],\n",
       "                        [-0.0524,  0.1093,  0.1006, -0.0206,  0.0003],\n",
       "                        [-0.0949,  0.0140,  0.0844, -0.0635, -0.1073]],\n",
       "              \n",
       "                       [[-0.0528, -0.0315, -0.0328,  0.0952, -0.1092],\n",
       "                        [ 0.1041,  0.0605, -0.0946,  0.0881, -0.0947],\n",
       "                        [-0.0273, -0.0771, -0.0155, -0.0349, -0.0541],\n",
       "                        [-0.0264, -0.0682,  0.0857,  0.0488, -0.0032],\n",
       "                        [ 0.0217, -0.0002,  0.0854, -0.0867,  0.0320]],\n",
       "              \n",
       "                       [[ 0.1164, -0.0116,  0.0968, -0.0130,  0.0548],\n",
       "                        [-0.0518,  0.0068, -0.0038,  0.0133, -0.0789],\n",
       "                        [-0.0795, -0.0104,  0.0593, -0.0705, -0.0520],\n",
       "                        [ 0.0095, -0.0649, -0.0425,  0.0451, -0.0058],\n",
       "                        [-0.0738,  0.0629,  0.0399,  0.1108,  0.0177]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0876, -0.0485,  0.0830,  0.0017,  0.0578],\n",
       "                        [-0.0037,  0.0710,  0.1203,  0.0816,  0.0849],\n",
       "                        [ 0.1079,  0.0802,  0.0501, -0.0223,  0.0895],\n",
       "                        [ 0.1401, -0.0736,  0.1333,  0.0857, -0.0271],\n",
       "                        [ 0.0413, -0.0420,  0.0347,  0.1552,  0.0441]],\n",
       "              \n",
       "                       [[ 0.1321,  0.0962,  0.0422,  0.0394, -0.0169],\n",
       "                        [-0.0345,  0.0089, -0.0110, -0.0767, -0.0031],\n",
       "                        [-0.0100, -0.0446,  0.0878,  0.0532, -0.0341],\n",
       "                        [ 0.1181, -0.0868, -0.0952, -0.1007, -0.1023],\n",
       "                        [ 0.0486,  0.0047,  0.0599, -0.0863,  0.0185]],\n",
       "              \n",
       "                       [[ 0.1007,  0.1801,  0.1799,  0.0866, -0.0206],\n",
       "                        [ 0.1776,  0.1914,  0.1559,  0.0817,  0.0482],\n",
       "                        [ 0.0381,  0.1458,  0.1429,  0.1457, -0.0306],\n",
       "                        [ 0.0051,  0.0319, -0.0020,  0.0144,  0.0033],\n",
       "                        [ 0.0656,  0.0347,  0.0942,  0.0429,  0.0758]]]])),\n",
       "             ('conv1.bias',\n",
       "              tensor([-0.0216, -0.0588,  0.3790, -0.0394, -0.0581, -0.2188])),\n",
       "             ('conv2.weight',\n",
       "              tensor([[[[ 0.0308, -0.0628, -0.0732,  0.0323,  0.0101],\n",
       "                        [ 0.0307, -0.0805, -0.0651, -0.0466, -0.1085],\n",
       "                        [-0.0128,  0.0287, -0.0008,  0.0447, -0.0744],\n",
       "                        [ 0.0343, -0.0832,  0.0022, -0.0373, -0.0810],\n",
       "                        [-0.0181,  0.0370, -0.0358, -0.0338,  0.0279]],\n",
       "              \n",
       "                       [[ 0.2285,  0.1422,  0.1763,  0.2240,  0.1146],\n",
       "                        [ 0.1439,  0.1618,  0.1865,  0.0510,  0.0872],\n",
       "                        [ 0.1262,  0.0213,  0.0149,  0.1188,  0.0661],\n",
       "                        [ 0.1265,  0.1256,  0.0593,  0.0694,  0.0481],\n",
       "                        [ 0.0767, -0.0468,  0.0117, -0.0450,  0.0162]],\n",
       "              \n",
       "                       [[-0.1264, -0.0404, -0.0061, -0.0673, -0.1040],\n",
       "                        [-0.0326, -0.0560, -0.0734, -0.0758, -0.0934],\n",
       "                        [-0.0917, -0.0072,  0.0399, -0.0073, -0.0431],\n",
       "                        [-0.0072, -0.0900, -0.0384, -0.0386,  0.0187],\n",
       "                        [-0.0565, -0.0986, -0.0340, -0.0712,  0.0310]],\n",
       "              \n",
       "                       [[-0.0278, -0.0172,  0.0296,  0.0409, -0.0317],\n",
       "                        [-0.0535, -0.0479,  0.0060, -0.0322,  0.0375],\n",
       "                        [-0.0583,  0.0616,  0.0190, -0.0386, -0.0026],\n",
       "                        [ 0.0348, -0.0635,  0.0075,  0.0462,  0.0145],\n",
       "                        [-0.0435,  0.0750,  0.0854,  0.0499, -0.0421]],\n",
       "              \n",
       "                       [[-0.0756, -0.0796,  0.0035, -0.0357, -0.0637],\n",
       "                        [ 0.0652, -0.0583, -0.0016,  0.0105,  0.0733],\n",
       "                        [-0.0521, -0.0796, -0.0674, -0.0274, -0.0489],\n",
       "                        [ 0.0601, -0.0294, -0.0662, -0.0000,  0.0631],\n",
       "                        [ 0.0442,  0.0798, -0.0494,  0.0342, -0.0680]],\n",
       "              \n",
       "                       [[-0.0242,  0.0205,  0.0273, -0.0318, -0.0664],\n",
       "                        [-0.0266, -0.0442, -0.0532,  0.0336,  0.0378],\n",
       "                        [ 0.0757,  0.0634,  0.0320, -0.0883, -0.0455],\n",
       "                        [-0.0068,  0.0849,  0.0597, -0.0341,  0.0835],\n",
       "                        [ 0.0715,  0.0099, -0.0421,  0.0736,  0.0248]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0674, -0.0978, -0.0798, -0.0643, -0.0143],\n",
       "                        [-0.0031, -0.0508,  0.0409,  0.0654,  0.0492],\n",
       "                        [-0.0745, -0.0130, -0.0488,  0.0416,  0.0989],\n",
       "                        [-0.0122, -0.0572,  0.0552,  0.0895, -0.0298],\n",
       "                        [-0.0882, -0.0658,  0.0159,  0.0998,  0.0553]],\n",
       "              \n",
       "                       [[ 0.0625,  0.0819, -0.0155, -0.0756, -0.0160],\n",
       "                        [ 0.0609,  0.0329, -0.0542, -0.0571, -0.0729],\n",
       "                        [ 0.0988,  0.0919, -0.0783, -0.0103, -0.0624],\n",
       "                        [ 0.0869,  0.0088, -0.0585, -0.0223, -0.0638],\n",
       "                        [ 0.0651, -0.0666,  0.0155,  0.0414,  0.0612]],\n",
       "              \n",
       "                       [[ 0.0366, -0.0097,  0.0385,  0.0330,  0.0460],\n",
       "                        [-0.0810, -0.0643, -0.0876,  0.0784,  0.0375],\n",
       "                        [-0.0287, -0.1082, -0.0075,  0.0043,  0.0404],\n",
       "                        [-0.1035, -0.0569,  0.0961,  0.0439,  0.0295],\n",
       "                        [ 0.0222,  0.0203,  0.0716,  0.0315,  0.0652]],\n",
       "              \n",
       "                       [[-0.0597,  0.0392,  0.0709, -0.0192,  0.0344],\n",
       "                        [ 0.0110,  0.0491,  0.0284,  0.0013,  0.0037],\n",
       "                        [ 0.0599, -0.0722, -0.0097, -0.0192, -0.0598],\n",
       "                        [ 0.0518, -0.0156, -0.0494, -0.0542,  0.0329],\n",
       "                        [-0.0789, -0.0251, -0.0788,  0.0414,  0.0489]],\n",
       "              \n",
       "                       [[-0.0743,  0.0730, -0.0700, -0.0493,  0.0350],\n",
       "                        [ 0.0439,  0.0660,  0.0448,  0.0609,  0.0060],\n",
       "                        [-0.0669,  0.0472, -0.0156, -0.0808, -0.0274],\n",
       "                        [-0.0601, -0.0695,  0.0554, -0.0339, -0.0400],\n",
       "                        [ 0.0312, -0.0298, -0.0753,  0.0603,  0.0484]],\n",
       "              \n",
       "                       [[ 0.0703,  0.0396,  0.0250, -0.0179, -0.0326],\n",
       "                        [-0.0491,  0.0053, -0.0538,  0.0396,  0.0416],\n",
       "                        [ 0.0031,  0.0836, -0.0140,  0.0033,  0.0148],\n",
       "                        [ 0.0337, -0.0267,  0.0357, -0.0619,  0.0163],\n",
       "                        [ 0.0856,  0.0172, -0.0795, -0.0688, -0.0501]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0512, -0.0584,  0.0695,  0.0121, -0.0378],\n",
       "                        [-0.0347, -0.0010,  0.0465, -0.0760, -0.0816],\n",
       "                        [ 0.0432, -0.0079,  0.0117, -0.0636, -0.0225],\n",
       "                        [ 0.0119, -0.0550, -0.0605, -0.0217, -0.0776],\n",
       "                        [-0.0211,  0.0026,  0.0213, -0.0705, -0.0081]],\n",
       "              \n",
       "                       [[-0.0456,  0.0307, -0.0806, -0.0410, -0.0777],\n",
       "                        [ 0.0065, -0.0722, -0.0287,  0.0577, -0.0292],\n",
       "                        [-0.0536,  0.0015, -0.0404, -0.0255, -0.0535],\n",
       "                        [-0.0631, -0.0178, -0.0495, -0.0183, -0.0495],\n",
       "                        [-0.0187,  0.0329,  0.0051,  0.0560, -0.0643]],\n",
       "              \n",
       "                       [[ 0.0213,  0.0313,  0.0002, -0.0673,  0.0077],\n",
       "                        [ 0.0501,  0.0291, -0.0590, -0.0507,  0.0705],\n",
       "                        [ 0.0201, -0.0079, -0.0817,  0.0466, -0.0493],\n",
       "                        [ 0.0321,  0.0671,  0.0468,  0.0056, -0.0415],\n",
       "                        [ 0.0178,  0.0220, -0.0211, -0.0239, -0.0327]],\n",
       "              \n",
       "                       [[-0.0165,  0.0127, -0.0796, -0.0572, -0.0788],\n",
       "                        [ 0.0788,  0.0531,  0.0322,  0.0283,  0.0672],\n",
       "                        [ 0.0176, -0.0193, -0.0174, -0.0243,  0.0207],\n",
       "                        [-0.0079, -0.0008, -0.0726,  0.0038, -0.0336],\n",
       "                        [ 0.0683,  0.0640, -0.0675, -0.0126,  0.0041]],\n",
       "              \n",
       "                       [[-0.0208,  0.0759,  0.0215,  0.0317, -0.0129],\n",
       "                        [ 0.0283,  0.0009,  0.0031,  0.0624,  0.0116],\n",
       "                        [ 0.0062, -0.0380, -0.0499, -0.0119, -0.0721],\n",
       "                        [ 0.0712,  0.0521,  0.0246,  0.0625,  0.0510],\n",
       "                        [-0.0502,  0.0194, -0.0190, -0.0748,  0.0221]],\n",
       "              \n",
       "                       [[-0.0576,  0.0167, -0.0734, -0.0419, -0.0728],\n",
       "                        [ 0.0521,  0.0585,  0.0280,  0.0774,  0.0157],\n",
       "                        [-0.0672, -0.0730,  0.0011, -0.0030,  0.0522],\n",
       "                        [-0.0074, -0.0582,  0.0239,  0.0705, -0.0741],\n",
       "                        [ 0.0200,  0.0663, -0.0509, -0.0447, -0.0417]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0140,  0.0066,  0.0640, -0.0458,  0.0301],\n",
       "                        [ 0.0379, -0.0534, -0.0778,  0.0163, -0.0081],\n",
       "                        [-0.0237,  0.0186, -0.0485, -0.0571, -0.0101],\n",
       "                        [-0.0284,  0.0364, -0.0042, -0.0591,  0.0620],\n",
       "                        [-0.0071, -0.0074, -0.0151,  0.0501, -0.0233]],\n",
       "              \n",
       "                       [[ 0.0280,  0.0474,  0.1183,  0.0641,  0.0860],\n",
       "                        [ 0.1092,  0.0870,  0.0700,  0.0882,  0.0671],\n",
       "                        [ 0.0768,  0.0394,  0.0432,  0.0184,  0.0125],\n",
       "                        [-0.0082, -0.0246,  0.0257,  0.0652, -0.0326],\n",
       "                        [-0.0486, -0.0484,  0.0316,  0.0967,  0.0971]],\n",
       "              \n",
       "                       [[-0.0032,  0.0657,  0.0006,  0.0743, -0.0242],\n",
       "                        [-0.0130,  0.0407, -0.0506,  0.0356,  0.0071],\n",
       "                        [ 0.0035, -0.0057, -0.0371, -0.0230, -0.0161],\n",
       "                        [ 0.0176,  0.0144,  0.0811,  0.0813, -0.0344],\n",
       "                        [ 0.0304, -0.0247, -0.0600, -0.0352,  0.0839]],\n",
       "              \n",
       "                       [[-0.0702, -0.0724,  0.0320,  0.0106, -0.0033],\n",
       "                        [ 0.0627, -0.0543, -0.0822, -0.0390, -0.0365],\n",
       "                        [ 0.0198, -0.0188, -0.0803,  0.0188, -0.0133],\n",
       "                        [-0.0281,  0.0622, -0.0462, -0.0125, -0.0419],\n",
       "                        [ 0.0584,  0.0021,  0.0352, -0.0060, -0.0821]],\n",
       "              \n",
       "                       [[ 0.0492, -0.0151,  0.0396, -0.0798, -0.0321],\n",
       "                        [-0.0793, -0.0723, -0.0698,  0.0384, -0.0054],\n",
       "                        [-0.0172, -0.0433,  0.0348,  0.0695,  0.0396],\n",
       "                        [-0.0366,  0.0012, -0.0112,  0.0602,  0.0458],\n",
       "                        [ 0.0264, -0.0078,  0.0026, -0.0359,  0.0028]],\n",
       "              \n",
       "                       [[ 0.0509, -0.0482, -0.0077,  0.0170,  0.0198],\n",
       "                        [-0.0089, -0.0027, -0.0906,  0.0543, -0.0865],\n",
       "                        [-0.0955, -0.0934, -0.0373,  0.0155, -0.0302],\n",
       "                        [-0.0041,  0.0055, -0.0595,  0.0189, -0.0246],\n",
       "                        [-0.0853, -0.0052, -0.0259, -0.0178, -0.0764]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0619,  0.0161, -0.0187, -0.0759, -0.0470],\n",
       "                        [ 0.0375, -0.0653,  0.0285,  0.0179,  0.0464],\n",
       "                        [ 0.0463,  0.0366,  0.0024,  0.0572,  0.0326],\n",
       "                        [ 0.0377,  0.0998, -0.0625,  0.0375,  0.0165],\n",
       "                        [-0.0490,  0.0386,  0.0836, -0.0204,  0.1027]],\n",
       "              \n",
       "                       [[-0.0133, -0.0131,  0.0285, -0.0687,  0.0714],\n",
       "                        [-0.0577, -0.0475, -0.0311, -0.0992, -0.0925],\n",
       "                        [ 0.0005,  0.0339, -0.0042, -0.0516,  0.0297],\n",
       "                        [-0.0909, -0.0350, -0.0586, -0.0753, -0.0675],\n",
       "                        [-0.0428,  0.0665, -0.0326, -0.0273,  0.0516]],\n",
       "              \n",
       "                       [[-0.0658, -0.0411, -0.0595, -0.0431, -0.0860],\n",
       "                        [-0.0140,  0.0030,  0.0625, -0.0261, -0.0954],\n",
       "                        [ 0.0675,  0.0758, -0.0315, -0.0668,  0.0634],\n",
       "                        [ 0.0474,  0.0166, -0.0275,  0.0889,  0.0578],\n",
       "                        [ 0.0226, -0.0448,  0.0467, -0.0429,  0.1058]],\n",
       "              \n",
       "                       [[-0.0708, -0.0375,  0.0761,  0.0246, -0.0147],\n",
       "                        [-0.0399,  0.0321, -0.0506,  0.0176,  0.0884],\n",
       "                        [ 0.0262, -0.0457, -0.0179, -0.0077,  0.0350],\n",
       "                        [-0.0485, -0.0220,  0.0841,  0.0306,  0.0818],\n",
       "                        [ 0.0382, -0.0229,  0.0864, -0.0620, -0.0539]],\n",
       "              \n",
       "                       [[ 0.0488, -0.0193, -0.0338, -0.0740, -0.0311],\n",
       "                        [-0.0543, -0.0032, -0.0641,  0.0124,  0.0708],\n",
       "                        [ 0.0816,  0.0542, -0.0479, -0.0364,  0.0111],\n",
       "                        [-0.0249,  0.0653, -0.0701, -0.0018, -0.0766],\n",
       "                        [-0.0496, -0.0752,  0.0368,  0.0251,  0.0183]],\n",
       "              \n",
       "                       [[-0.0103,  0.0720,  0.0656,  0.0516,  0.0250],\n",
       "                        [-0.0610, -0.0434, -0.0029,  0.0934,  0.0641],\n",
       "                        [ 0.0581,  0.0414, -0.0554,  0.0424,  0.0950],\n",
       "                        [ 0.0238,  0.0373,  0.0220,  0.0646,  0.0523],\n",
       "                        [-0.0221,  0.0560,  0.0483, -0.0474,  0.0611]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0398, -0.0560, -0.0487, -0.1133,  0.0127],\n",
       "                        [ 0.0027, -0.0284, -0.1098,  0.0088, -0.0039],\n",
       "                        [ 0.0559, -0.0864,  0.0410, -0.0632, -0.0056],\n",
       "                        [ 0.0876,  0.0433,  0.0471, -0.0975, -0.0304],\n",
       "                        [-0.0061,  0.0970,  0.0830, -0.0729,  0.0172]],\n",
       "              \n",
       "                       [[ 0.0960,  0.0114,  0.1212,  0.0475,  0.0277],\n",
       "                        [ 0.0577, -0.0422,  0.1026, -0.0235,  0.0303],\n",
       "                        [-0.0804,  0.0586, -0.0484,  0.0616,  0.0425],\n",
       "                        [-0.0367,  0.0415, -0.0359, -0.1044,  0.0177],\n",
       "                        [-0.1384, -0.1173, -0.0123, -0.0424, -0.0306]],\n",
       "              \n",
       "                       [[-0.0888, -0.0726, -0.1185, -0.0088, -0.1302],\n",
       "                        [-0.1037,  0.0037, -0.0040,  0.0026, -0.0202],\n",
       "                        [-0.0482,  0.0313,  0.0388, -0.1203,  0.0209],\n",
       "                        [ 0.0422,  0.0628, -0.0447, -0.0566, -0.0967],\n",
       "                        [ 0.0603,  0.0872, -0.0095,  0.0400, -0.0501]],\n",
       "              \n",
       "                       [[ 0.0327,  0.0191,  0.0235, -0.0832, -0.0970],\n",
       "                        [ 0.0247,  0.0576, -0.0133, -0.0005,  0.0110],\n",
       "                        [ 0.0655,  0.0246,  0.0093, -0.0562, -0.0642],\n",
       "                        [-0.0484,  0.0886,  0.0163,  0.0846, -0.0135],\n",
       "                        [ 0.0492,  0.0368, -0.0096,  0.0329,  0.0797]],\n",
       "              \n",
       "                       [[-0.0364,  0.0080,  0.0177, -0.0243,  0.0653],\n",
       "                        [-0.0732,  0.0057,  0.0421,  0.0664,  0.0195],\n",
       "                        [-0.0283, -0.0714, -0.0147, -0.0543,  0.0567],\n",
       "                        [ 0.0556,  0.0586,  0.0303,  0.0240, -0.0455],\n",
       "                        [ 0.0136,  0.0463, -0.0016,  0.0773,  0.0472]],\n",
       "              \n",
       "                       [[ 0.0013,  0.0341,  0.0479,  0.0514, -0.0155],\n",
       "                        [ 0.0977,  0.0690,  0.0592,  0.0237, -0.0386],\n",
       "                        [ 0.1278,  0.1268,  0.0534,  0.1096, -0.0247],\n",
       "                        [ 0.1319,  0.1189,  0.1201,  0.0764, -0.0184],\n",
       "                        [ 0.0634,  0.0796,  0.1251,  0.0020,  0.1174]]]])),\n",
       "             ('conv2.bias', tensor(1.00000e-02 *\n",
       "                     [ 1.2918, -1.2585, -3.8799,  2.7891, -6.4843, -8.1292, -2.4841,\n",
       "                       1.3448, -3.4055, -3.3052, -5.2191, -1.4692, -5.7857, -8.9859,\n",
       "                      -4.0093, -1.6340])),\n",
       "             ('fc1.weight',\n",
       "              tensor([[ 1.9693e-02, -2.5104e-03,  3.5926e-02,  ...,  2.3257e-03,\n",
       "                        1.4487e-02, -2.7230e-02],\n",
       "                      [ 1.1399e-02,  4.1457e-02, -1.0029e-05,  ...,  3.7992e-02,\n",
       "                        3.2913e-02,  1.1647e-02],\n",
       "                      [-2.3354e-02,  2.1788e-02,  2.6254e-02,  ..., -2.2817e-02,\n",
       "                       -8.0975e-03, -2.1985e-02],\n",
       "                      ...,\n",
       "                      [ 1.5424e-02,  1.5831e-02,  2.2425e-02,  ..., -1.9254e-02,\n",
       "                       -2.0479e-02, -2.0425e-02],\n",
       "                      [ 2.2819e-02,  9.2192e-03,  3.4117e-03,  ..., -2.5398e-02,\n",
       "                        4.1489e-03, -2.4427e-02],\n",
       "                      [ 7.7753e-03,  1.9788e-02,  1.1700e-02,  ...,  2.1889e-02,\n",
       "                       -2.4062e-02, -2.1324e-02]])),\n",
       "             ('fc1.bias', tensor(1.00000e-02 *\n",
       "                     [ 1.7618, -1.2642, -1.5421,  2.3722,  0.3181, -1.2437, -0.7511,\n",
       "                       2.5363, -3.2465,  0.3655, -2.2046, -0.2999,  0.7357, -0.6087,\n",
       "                       3.4234,  2.7209, -1.3704,  1.9128,  0.4469, -2.7290,  1.1872,\n",
       "                      -0.5084, -2.8781, -1.9340, -0.1020,  1.7537, -3.0945, -1.1931,\n",
       "                       3.5724, -1.8289, -0.1393, -2.1090,  0.9907, -1.7520,  1.7882,\n",
       "                      -0.2667,  2.7241,  4.3337,  1.6317,  4.1604, -0.0072, -0.7559,\n",
       "                       3.0220, -0.0862, -2.7370, -2.9279, -0.6811,  2.3992, -0.2987,\n",
       "                       1.4231,  1.0284,  4.2250,  0.6415, -0.6144,  0.0148,  1.0555,\n",
       "                      -3.7415,  2.0922,  0.0419, -2.4936, -0.1462, -0.5602,  0.0502,\n",
       "                       1.6810, -1.3117, -1.7460, -1.2916,  0.5930,  4.3600, -0.8820,\n",
       "                       1.9731, -3.4589, -2.3175,  0.9077,  2.7476, -1.7415, -3.4934,\n",
       "                      -1.9000,  1.6607, -0.2452, -2.1056,  1.2016,  2.6966,  3.4718,\n",
       "                      -3.0293,  0.1869,  0.0661, -0.6995, -1.2647,  0.3838,  2.4016,\n",
       "                       1.0340, -0.4325,  1.3928,  2.4965,  0.8834,  1.8432, -3.0571,\n",
       "                       2.9672,  2.3291,  0.2315, -2.3585, -0.3322, -0.7356,  2.1857,\n",
       "                      -4.4340,  2.5482, -2.5986, -2.1727,  2.6364,  0.6882, -0.3901,\n",
       "                       0.8883,  2.6138, -1.4402,  1.7494, -0.3960, -2.3034,  3.8139,\n",
       "                      -3.1552,  3.0500,  0.0960, -3.1688, -0.0177, -0.6300,  1.1386,\n",
       "                      -2.8858,  0.3623])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[-0.0524, -0.1064,  0.0567,  ...,  0.0218, -0.0644,  0.0009],\n",
       "                      [ 0.0727,  0.0420,  0.0638,  ...,  0.0812, -0.0169, -0.0841],\n",
       "                      [-0.0383, -0.0578, -0.0084,  ..., -0.0285,  0.0005,  0.0032],\n",
       "                      ...,\n",
       "                      [-0.0104,  0.0548,  0.0702,  ..., -0.0112, -0.0014,  0.0188],\n",
       "                      [ 0.0338, -0.0622, -0.0548,  ...,  0.0520,  0.0330, -0.0040],\n",
       "                      [-0.0725,  0.0553,  0.0377,  ...,  0.0167, -0.0006, -0.0381]])),\n",
       "             ('fc2.bias',\n",
       "              tensor([ 0.1002,  0.0908,  0.1427,  0.0997, -0.0742, -0.0311,  0.0034,\n",
       "                       0.1042,  0.0730,  0.0499,  0.0020,  0.0172,  0.0785, -0.0603,\n",
       "                       0.0859,  0.1334, -0.0809, -0.0868, -0.0061,  0.0633,  0.1302,\n",
       "                       0.1320,  0.0259, -0.0278, -0.0080, -0.0674,  0.0497, -0.0735,\n",
       "                       0.0189, -0.0819, -0.0081, -0.0036])),\n",
       "             ('fc3.weight',\n",
       "              tensor([[-0.2344,  0.2611, -0.1701, -0.1772, -0.0881, -0.0152,  0.4954,\n",
       "                       -0.2024, -0.1721,  0.3885, -0.1648,  0.1406,  0.1888, -0.0225,\n",
       "                        0.0464, -0.4301, -0.0406, -0.0896,  0.0726, -0.1322, -0.1990,\n",
       "                       -0.4259, -0.1712,  0.0297, -0.0035,  0.1902,  0.1463,  0.1099,\n",
       "                        0.1460,  0.0527, -0.0607,  0.0330],\n",
       "                      [ 0.3296, -0.1548,  0.2828,  0.2250,  0.0158,  0.0266, -0.3192,\n",
       "                        0.2775, -0.0040, -0.3464,  0.1321, -0.0675, -0.3384, -0.0284,\n",
       "                        0.1716,  0.4467,  0.1295, -0.0709,  0.1888,  0.0026,  0.1777,\n",
       "                        0.3623, -0.0847, -0.1266,  0.0214, -0.1336, -0.0627,  0.2029,\n",
       "                        0.0221,  0.1328,  0.0999, -0.0595]])),\n",
       "             ('fc3.bias', tensor(1.00000e-02 *\n",
       "                     [-1.4640,  4.9841]))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mynet.load_state_dict(torch.load(models_path[-1])())\n",
    "mynet.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Test step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.57% accuracy on the test set\n"
     ]
    }
   ],
   "source": [
    "errors = 0\n",
    "mynet.eval()\n",
    "\n",
    "for i, data in enumerate(testset):\n",
    "    inputs, labels = data\n",
    "    inputs, labels = Variable(inputs), Variable(labels)\n",
    "    outputs = mynet(inputs)\n",
    "    _,y = torch.max(outputs,1)\n",
    "    errors += (y!=labels).sum().item()\n",
    "    \n",
    "accuracy = 1-errors/len(testset)\n",
    "print('{:0.2f}% accuracy on the test set'.format(100*accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clown Fish\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAAmCElEQVR4nAXBZ6xs+WEQ8H89dc6c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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x124549E80>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(RESULT[y[0].item()])\n",
    "transforms.ToPILImage()(inputs[0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
